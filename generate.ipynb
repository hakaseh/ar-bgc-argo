{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ***Generate*** the analysis-ready dataset of a selected BGC-Argo float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">--- User input begins ---</span>\n",
    "- `wmoid`: the float's WMO\n",
    "- `qc2keep`: value(s) of QC flags to be considered valid (\\['1','2','5','8'\\] is a standard choice, but modify as necessary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmoid = 6903574\n",
    "qc2keep = ['1','2','5','8']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">--- User input ends ---</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import generic_filter\n",
    "import pvlib\n",
    "import gsw\n",
    "import scipy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Load the input file (Sprof.nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = str(wmoid)+\"/\"+str(wmoid)+\"_Sprof.nc\"\n",
    "ds = xr.open_dataset(in_file) \n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Read all profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for storing all profiles\n",
    "varis = ['temp','psal','down','nitr','chla','bbp7','doxy','ph_i'] # shortened names\n",
    "vars_original = ['TEMP_ADJUSTED','PSAL_ADJUSTED', # original names\n",
    "                 'DOWNWELLING_PAR_ADJUSTED','NITRATE_ADJUSTED',\n",
    "                 'CHLA_ADJUSTED','BBP700_ADJUSTED',\n",
    "                 'DOXY_ADJUSTED','PH_IN_SITU_TOTAL_ADJUSTED']\n",
    "cmap_vars = ['inferno', 'cividis','viridis','magma','Greens','plasma','Blues','Oranges'] # colormap for each variable\n",
    "qc = {f\"{var}\": [] for var in varis} # qc flags\n",
    "qc_valid = {f\"{var}\": [] for var in varis} # good data\n",
    "pres_qc_valid = {f\"{var}\": [] for var in varis} # corresponding pres for good data\n",
    "npq5_qc_valid = [] # corresponding qc=5 for good chla data (used for identifying whether npq correction is needed)\n",
    "daytime_valid = []\n",
    "\n",
    "\n",
    "def calc_solar_elevation_vectorized(latitude, longitude, times):\n",
    "    \"\"\"\n",
    "    Calculates solar elevation in a fully vectorized way.\n",
    "    Inputs must be array-like (lists, np.array, pd.Series)\n",
    "    of matching lengths.\n",
    "    \n",
    "    Args:\n",
    "        latitude (array-like): Latitudes\n",
    "        longitude (array-like): Longitudes\n",
    "        times (pd.DatetimeIndex or array-like): Timezone-aware datetimes\n",
    "    \"\"\"\n",
    "    \n",
    "    # This function handles the element-wise calculation\n",
    "    solar_position = pvlib.solarposition.get_solarposition(\n",
    "        times, \n",
    "        latitude, \n",
    "        longitude\n",
    "    )\n",
    "    \n",
    "    solar_elevation = 90 - solar_position['zenith'].values\n",
    "    \n",
    "    # This returns a pandas Series (or a numpy array \n",
    "    # if you pass numpy arrays as input)\n",
    "    return solar_elevation\n",
    "\n",
    "\n",
    "def calc_solar_elevation(latitude, longitude, utc):\n",
    "    loc = pvlib.location.Location(latitude, longitude)\n",
    "    solar_position = loc.get_solarposition(utc)\n",
    "    solar_zenith = solar_position['zenith'].values[0]  \n",
    "    solar_elevation = 90 - solar_zenith\n",
    "    return solar_elevation\n",
    "\n",
    "# Determine whether to use PRES or PRES_ADJUSTED\n",
    "# use PRES if all values are NaN for PRES_ADJUSTED\n",
    "if np.isnan(ds['PRES_ADJUSTED'].values).all():\n",
    "    use_pres = \"PRES\"\n",
    "# use PRES_ADJUSTED if non-NaN values exist\n",
    "else:\n",
    "    use_pres = \"PRES_ADJUSTED\"\n",
    "\n",
    "daytime_valid = calc_solar_elevation_vectorized(ds['LATITUDE'].values,ds['LONGITUDE'].values,ds['JULD'].values) > 0 # True if sun is above horizon (daytime)\n",
    "\n",
    "# two xarrays are returned\n",
    "def ds_valid(name_in,qc_valid):\n",
    "    qc_mask = ds[name_in+\"_QC\"].astype(str).isin(qc_valid)\n",
    "    return ds[name_in].where(qc_mask,other=np.nan),ds[use_pres].where(qc_mask,other=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?unnecessary?\n",
    "for j in range(len(varis)): # loop over variables\n",
    "    # if the variable is included in the profile\n",
    "    if vars_original[j] in ds.data_vars:\n",
    "        raw[varis[j]].append(ds[vars_original[j]][:,:].values) # store raw profiles\n",
    "        qc[varis[j]].append(ds[vars_original[j]+'_QC'][:,:].values.astype(str)) # store qc flags\n",
    "        qc_valid[varis[j]].append(raw[varis[j]][-1][np.isin(qc[varis[j]][-1],qc2keep)]) # store qc masks\n",
    "        if vars_original[j] == 'CHLA_ADJUSTED': # include the qc flag of 5 (NPQ)\n",
    "            npq5_qc_valid.append(np.any(np.isin(qc[varis[j]][-1],['5']))) # set to True if the profile contains QC of 5 (NPQ corrected)\n",
    "    # set to nan if the variable is missing in the current profile\n",
    "    else:\n",
    "        raw[varis[j]].append([np.nan]*len(pres[-1]))\n",
    "        qc[varis[j]].append([np.nan]*len(pres[-1]))\n",
    "        qc_valid[varis[j]].append([np.nan]*len(pres[-1])) # set to nan as the variable is missing\n",
    "        if vars_original[j] == 'CHLA_ADJUSTED': # include the qc flag of 5 (NPQ)\n",
    "            npq5_qc_valid.append([np.nan]*len(pres[-1])) # set to nan as the variable is missing\n",
    "    pres_qc_valid[varis[j]].append(pres[-1][np.isin(qc[varis[j]][-1],qc2keep)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Define a function for scatter plotting (used for raw, good, and smoothed data visualization, because pcolormesh does not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(ds_in,ds_pres_in,name_in,cmap_in):\n",
    "    ds_min,ds_max = ds_in.min(),ds_in.max()\n",
    "    for i in range(ds_in[\"N_PROF\"].size): # loop over profiles\n",
    "#unnecessary?        if np.any(np.isfinite(vari_in[i])): # ignore the profile with all NaNs\n",
    "        plt.scatter(x=np.full(len(ds_pres_in[i,:]),ds[\"JULD\"].values[i]),y=ds_pres_in[i,:],c=ds_in[i,:],s=0.1,cmap=cmap_in,\n",
    "                    vmin=ds_min,vmax=ds_max\n",
    "                   )\n",
    "    plt.gca().invert_yaxis()\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(name_in)\n",
    "    vari_ptile = [ds_in.quantile(0.25).values,\n",
    "                  ds_in.quantile(0.50).values,\n",
    "                  ds_in.quantile(0.75).values\n",
    "                 ]\n",
    "    cbar.ax.hlines(vari_ptile,xmin=0,xmax=1,color='r') # draw percentiles\n",
    "    plt.gcf().autofmt_xdate() # automatically format date\n",
    "    plt.xlim(ds[\"JULD\"].min(),ds[\"JULD\"].max()) # align the date range across all variables\n",
    "    plt.ylim(ds_pres_in.max(),ds_pres_in.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Plot the raw data to understand the data coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "for j in range(len(vars_original)): # loop over variables\n",
    "    plt.subplot(3,3,j+1)\n",
    "    if vars_original[j] in ds.data_vars and ds[vars_original[j]].notnull().any(): # if finite values exit\n",
    "        plot_scatter(ds[vars_original[j]],ds[use_pres],vars_original[j],cmap_vars[j])\n",
    "    else:\n",
    "        plt.text(0.1,0.5,'NO DATA for \\n'+vars_original[j])\n",
    "        plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(wmoid)+'/fig-raw-'+str(wmoid),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Plotting the good data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "for j in range(len(vars_original)): # loop over variables\n",
    "    plt.subplot(3,3,j+1)\n",
    "    if vars_original[j] in ds.data_vars and ds_valid(vars_original[j],qc2keep)[0].notnull().any(): # if finite values exit\n",
    "        plot_scatter(ds_valid(vars_original[j],qc2keep)[0],ds_valid(vars_original[j],qc2keep)[1],vars_original[j],cmap_vars[j])\n",
    "    else:\n",
    "        plt.text(0.1,0.5,'NO DATA for \\n'+vars_original[j])\n",
    "        plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(wmoid)+'/fig-good-'+str(wmoid),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Smoothing for chlorophyll-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_res_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CHLA_ADJUSTED\" in ds.data_vars and ds_valid(\"CHLA_ADJUSTED\",qc2keep)[0].notnull().any():\n",
    "    # valid pressure array for chla\n",
    "    pres_valid_chla = ds_valid(\"CHLA_ADJUSTED\",qc2keep)[1]\n",
    "    # vertical resolution\n",
    "    pres_res = pres_valid_chla.diff(dim=\"N_LEVELS\")\n",
    "    # midpoint depth at which vertical resolutions are defined\n",
    "    pres_mid = (pres_valid_chla[:,:-1] + pres_valid_chla[:,1:]) / 2\n",
    "    pres_res_med = pres_res.median(dim=\"N_LEVELS\")\n",
    "\n",
    "    # Compute and assign smoothed values\n",
    "    nsmooth = pres_res_med.copy(deep=True)\n",
    "    for i in range(pres_res_med.size): # loop over profiles\n",
    "        # window size\n",
    "        if pres_res_med[i] >= 3:\n",
    "            nsmooth[i] = 5\n",
    "        elif pres_res_med[i] <= 1:\n",
    "            nsmooth[i] = 11\n",
    "        else:\n",
    "            nsmooth[i] = 7\n",
    "    \n",
    "    result = ds_valid(\"CHLA_ADJUSTED\",qc2keep)[0].rolling(N_LEVELS=nsmooth, center=True, min_periods=1).median()\n",
    "\n",
    "if 1 == 0:\n",
    "    # median filter that ignores NaNs\n",
    "    def nanmedian_filter(values):\n",
    "        valid_values = values[~np.isnan(values)]\n",
    "        # set to median if valid values exit, set to NaN otherwise\n",
    "        return np.median(valid_values) if len(valid_values) > 0 else np.nan\n",
    "    \n",
    "\n",
    "        # apply median filter\n",
    "        smooth[varis[j]].append(generic_filter(\n",
    "            qc_valid[varis[j]][i],nanmedian_filter,size=nsmooth,mode='nearest')\n",
    "                              )\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12,10))\n",
    "    for j in range(len(varis)): # loop over variables\n",
    "        plt.subplot(3,3,j+1)\n",
    "        if len(smooth[varis[j]]) and np.any(np.isfinite(np.concatenate(smooth[varis[j]]))): # if finite values exit\n",
    "            plot_raw(smooth[varis[j]],pres_qc_valid[varis[j]],juld,vars_original[j],cmap_vars[j])\n",
    "        else:\n",
    "            plt.text(0.1,0.5,'NO DATA for \\n'+vars_original[j])\n",
    "            plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(wmoid)+'/fig-smooth-'+str(wmoid),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">--- User input begins ---</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_res = 5 # vertical resolution used for interpolation (in dbar)\n",
    "int_dep0 = 1.0 # the shallowest depth\n",
    "int_dep1 = 1000.0 # the deepest depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">--- User input ends ---</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "- date is sorted for 2d interpolation\n",
    "- Set negatives to zeros for all variables other than temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_int = np.arange(int_dep0,int_dep1,int_res) # depth grid for interpolation\n",
    "data_int = {f\"{var}\": [] for var in varis} # interpolated data\n",
    "\n",
    "def interpolate_argo(pres_in,pres_out,data_in,date,vari_name_in):\n",
    "    data2d = np.full((len(date),len(pres_out)), np.nan) # create 2d array filled with NaNs\n",
    "    for i in range(len(pres_in)):\n",
    "        if np.any(np.isfinite(pres_in[i])): # ignore the profile with all NaNs\n",
    "            f = scipy.interpolate.interp1d(x=pres_in[i],y=data_in[i],\n",
    "                                           kind='linear',\n",
    "                                           bounds_error=False,  \n",
    "                                           fill_value=np.nan\n",
    "                                          )\n",
    "            data2d[i,:] = f(pres_out)\n",
    "    return np.float32(data2d) # single precision is sufficient\n",
    "\n",
    "# function to plot the interpolated data (2d array)\n",
    "def plot_int(vari_in,pres_in,juld_in,vari_name_in,cmap_in):\n",
    "    X, Y = np.meshgrid(juld_in,pres_in, indexing='ij')  # (time, depth)\n",
    "    if np.any(np.isfinite(vari_in)): # check at least one value exits\n",
    "        plt.pcolormesh(X,Y,vari_in,vmin=np.nanmin(vari_in),vmax=np.nanmax(vari_in),cmap=cmap_in)\n",
    "    else: # all values are NaNs, which seems weird\n",
    "        print('all interpolated values are NaN? CHECK')\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(vari_name_in)\n",
    "    vari_ptile = [np.nanpercentile(vari_in,25),\n",
    "                  np.nanpercentile(vari_in,50),\n",
    "                  np.nanpercentile(vari_in,75)\n",
    "                 ]\n",
    "    cbar.ax.hlines(vari_ptile,xmin=0,xmax=1,color='r') # draw percentiles\n",
    "    plt.gcf().autofmt_xdate() # automatically format date\n",
    "    plt.xlim(np.min(juld),np.max(juld)) # align the date range across all variables\n",
    "    plt.ylim(0,np.max(pres_in)) # align the depth range across all variables\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "# Interpolate and plot\n",
    "plt.figure(figsize=(12,10))\n",
    "for j in range(len(varis)): # loop over variables\n",
    "    plt.subplot(3,3,j+1)\n",
    "    if len(smooth[varis[j]]) and np.any(np.isfinite(np.concatenate(smooth[varis[j]]))): # if finite values exit\n",
    "        data_int[varis[j]] = interpolate_argo(pres_qc_valid[varis[j]],pres_int,smooth[varis[j]],juld,vars_original[j])\n",
    "        if varis[j] != 'temp': # if not temperature\n",
    "            data_int[varis[j]][data_int[varis[j]]<0] = 0 # set negatives to zeros\n",
    "        plot_int(data_int[varis[j]],pres_int,juld,vars_original[j],cmap_vars[j])        \n",
    "    else:\n",
    "        plt.text(0.1,0.5,'NO DATA for \\n'+vars_original[j])\n",
    "        plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(wmoid)+'/fig-int-'+str(wmoid),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Store as an xarray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to hold DataArrays\n",
    "data_vars = {}\n",
    "\n",
    "# Loop to generate DataArrays\n",
    "for i in range(len(varis)):\n",
    "    if len(data_int[varis[i]]): # continue if data exist\n",
    "        data_array = xr.DataArray(\n",
    "            data_int[varis[i]],\n",
    "            coords={\n",
    "                'time': ('time', juld), #, {'units': 'days since 1950-01-01'}),\n",
    "                'depth': ('depth', pres_int, {'units': 'dbar'})  # or 'meters' if it's depth below sea surface\n",
    "            },            \n",
    "            dims=['time', 'depth'],\n",
    "            attrs=ds[vars_original[i]].attrs # copy the input file attributes\n",
    "        )\n",
    "        data_vars[vars_original[i]+'_AR'] = data_array # adding the array to the dataset (AR: Analysis-Ready)\n",
    "    else: # skip if data are empty\n",
    "        print(vars_original[i],'is empty so not adding to the file')\n",
    "\n",
    "# add longitude and latitude as additonal variables in case of potential use\n",
    "data_vars['LONGITUDE'] = xr.DataArray(lon,coords={'time': ('time', juld)},dims=['time'],attrs=ds['LONGITUDE'].attrs)\n",
    "data_vars['LATITUDE'] = xr.DataArray(lat,coords={'time': ('time', juld)},dims=['time'],attrs=ds['LATITUDE'].attrs)\n",
    "\n",
    "# Create Dataset from all variables\n",
    "ds_int = xr.Dataset(data_vars)\n",
    "\n",
    "print(ds_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Extra\n",
    "- Non-Photochemical Quenching (NPQ) correction for chlrophyll-a\n",
    "- For all profiles collected during daytime, check whether NPQ correction was done (blue) or not (orange). It is unclear why some daytime profiles were NPQ corrected while others are not for some float, but it is possible that the correction was not done when some variables (e.g. T/S/CHLA) contained bad data.\n",
    "- Mixed layer depth based on the 0.03 kg m-3 threshold relative to the reference density at 10 dbar.\n",
    "- Sigma0, spiciness, and oxygen saturation concentration at 0 dbar calculated using GSW-Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty lists\n",
    "mld = [] # mixed layer depth\n",
    "sigma0 = [] # potential density anomaly\n",
    "chla_npq = data_int['chla'].copy() # NPQ corrected\n",
    "count_npq = 0 # number of NPQ correction applied here\n",
    "spiciness0 = [] \n",
    "O2sol = [] \n",
    "y_bottom = 300 # depth limit for plotting\n",
    "\n",
    "# MLD calculation\n",
    "if len(data_int['temp']) and len(data_int['psal']):\n",
    "    for i in range(len(data_int['temp'])): # loop over profiles        \n",
    "        if np.any(~np.isnan(data_int['temp'][i,:])) and np.any(~np.isnan(data_int['psal'][i,:])): # if good data exists\n",
    "            # Absolute Salinity\n",
    "            SA = gsw.SA_from_SP(data_int['psal'][i,:], pres_int, lon[i], lat[i])        \n",
    "            # Conservative Temperature\n",
    "            CT = gsw.CT_from_t(SA, data_int['temp'][i,:], pres_int)\n",
    "            # Saturation oxygen concentration (umol/kg)\n",
    "            O2sol.append(gsw.O2sol(SA,CT,pres_int,lon[i],lat[i]))\n",
    "            # Spiciness referenced to a pressure level of 0 dbar, i.e. at surface (kg/m^3)\n",
    "            spiciness0.append(gsw.spiciness0(SA,CT))\n",
    "            # Potential Density\n",
    "            sigma0.append(gsw.sigma0(SA, CT))\n",
    "            # Obtain sigma0 at 10 dbar based on linear interpolation\n",
    "            sigma0_10 = np.interp(10, pres_int, sigma0[-1])\n",
    "            for j in range(len(sigma0[-1])): # loop over samples\n",
    "                if sigma0[-1][j] > sigma0_10 + 0.03:\n",
    "                    mld.append(pres_int[j])\n",
    "                    idx90 = np.argmin(np.abs(pres_int - 0.9*mld[-1])) # depth index closest to mld*0.9\n",
    "                    if len(data_int['chla'] > 0):\n",
    "                        if np.any(~np.isnan(data_int['chla'][i, :])) and daytime_valid[i] and not npq5_qc_valid[i]: # if good data exists, sun is above horizon, and qc != 5 (NPQ correction necessary and possible)\n",
    "                            chla_npq[i,:idx90+1] = np.nanmax(chla_npq[i,:idx90+1]) # set the upper 90% mld to have uniform chla\n",
    "                            count_npq += 1 # count the number of corrected profiles\n",
    "                    break # stop at the first occurrence\n",
    "            else: # if the threshold is never met\n",
    "                mld.append(np.nan) # assign nan because MLD was not found\n",
    "        else:\n",
    "            mld.append(np.nan) # assign nan because no good temp and psal data exit\n",
    "            sigma0.append([np.nan]*len(pres_int))\n",
    "            O2sol.append([np.nan]*len(pres_int)) \n",
    "            spiciness0.append([np.nan]*len(pres_int))\n",
    "else:\n",
    "    print('Doing nothing as no temp and salt data exist (this should not happen...)')\n",
    "\n",
    "print('Total number of NPQ-corrected profiles in this step:',count_npq)\n",
    "\n",
    "# Add MLD as an additional variable\n",
    "ds_int['MLD'] = xr.DataArray(mld,coords={'time': ('time', juld)},dims=['time'],\n",
    "                                attrs={\n",
    "                                'long_name': 'Mixed layer depth based on 0.03 kg m-3 density criterion',\n",
    "                                'standard_name': 'mixed_layer_depth',\n",
    "                                'units': 'm',\n",
    "                                'valid_min': np.float32(0.0),\n",
    "                                'valid_max': np.float32(1000.0)\n",
    "                                }\n",
    "                               )\n",
    "\n",
    "# Add sigma0 as an additional variable\n",
    "ds_int['sigma0'] = xr.DataArray(\n",
    "    sigma0,\n",
    "    coords={\n",
    "        'time': ('time', juld),\n",
    "        'depth': ('depth', pres_int, {'units': 'dbar'})\n",
    "    },\n",
    "    dims=['time', 'depth'],\n",
    "    attrs={\n",
    "        'long_name': 'Potential density anomaly (sigma-0)',\n",
    "        'standard_name': 'sea_water_sigma_theta',\n",
    "        'comment': 'Potential density anomaly referenced to 0 dbar. See TEOS-10 for details.',\n",
    "        'units': 'kg/m^3 - 1000',  # or '1' (dimensionless, but often reported as \"kg/mÂ³ - 1000\")\n",
    "        'valid_min': np.float32(20.0),\n",
    "        'valid_max': np.float32(30.0)\n",
    "    }\n",
    ")\n",
    "# Add spiciness as an additional variable\n",
    "ds_int['SPICINESS0'] = xr.DataArray(spiciness0,\n",
    "                                   coords={'time': ('time', juld), \n",
    "                                           'depth': ('depth', pres_int, {'units': 'dbar'})\n",
    "                                          },\n",
    "                                   dims=['time', 'depth'],\n",
    "                                   attrs={\n",
    "                                    'long_name': 'Spiciness referenced to a pressure of 0 dbar',\n",
    "                                    'standard_name': 'spiciness',\n",
    "                                    'comment': 'see spiciness0 in https://teos-10.github.io/GSW-Python/gsw_flat.html',\n",
    "                                    'units': 'kg m-3',\n",
    "                                    'valid_min': np.float32(-100.0),\n",
    "                                    'valid_max': np.float32(100.0)\n",
    "                                    })\n",
    "\n",
    "# Add oxygen saturation as an additional variable\n",
    "ds_int['O2SOL'] = xr.DataArray(O2sol,\n",
    "                               coords={'time': ('time', juld), \n",
    "                                       'depth': ('depth', pres_int, {'units': 'dbar'})\n",
    "                                      },\n",
    "                               dims=['time', 'depth'],\n",
    "                               attrs={\n",
    "                                'long_name': 'Oxygen saturation concentration',\n",
    "                                'standard_name': 'moles_of_oxygen_per_unit_mass_in_sea_water',\n",
    "                                'comment': 'see O2sol in https://teos-10.github.io/GSW-Python/gsw_flat.html',\n",
    "                                'units': 'micromole/kg',\n",
    "                                'valid_min': np.float32(-5.0),\n",
    "                                'valid_max': np.float32(600.0)\n",
    "                                })\n",
    "\n",
    "# Visualize the calculated MLD and the effect of the NPQ correction.\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.subplot(331)\n",
    "plt.scatter(juld,ds_int['MLD'],zorder=3,s=1,c='k')\n",
    "plt.scatter([],[],s=1,c='k',label='MLD')\n",
    "if len(raw['chla']):\n",
    "    for i in range(len(juld)):\n",
    "        if daytime_valid[i]:\n",
    "            if npq5_qc_valid[i]:\n",
    "                plt.scatter(juld[i],y_bottom,marker='|',color='tab:blue',zorder=2)\n",
    "            else:\n",
    "                plt.scatter(juld[i],y_bottom,marker='|',color='tab:orange',zorder=2)\n",
    "    plt.scatter([],[],marker='|',color='tab:blue',label=r\"QC = 5 (DT)\")\n",
    "    plt.scatter([],[],marker='|',color='tab:orange',label=r\"QC $\\ne$ 5 (DT)\")\n",
    "    plt.legend()\n",
    "else:\n",
    "    print('CHLA_ADJUSTED is empty!')\n",
    "plt.legend()\n",
    "if count_npq > 0: # if NPQ correction was done\n",
    "    plot_int(data_int['chla'],pres_int,juld,'CHLA_ADJUSTED','Greens')\n",
    "    plt.ylim(y_bottom,0)\n",
    "    plt.subplot(332)\n",
    "    plot_int(chla_npq,pres_int,juld,'CHLA_ADJUSTED_NPQ','Greens')\n",
    "    plt.ylim(y_bottom,0)\n",
    "    plt.subplot(333)\n",
    "    diff = chla_npq - data_int['chla']\n",
    "    masked_diff = np.where(diff != 0, diff, np.nan)\n",
    "    plot_int(masked_diff,pres_int,juld,'NPQ-corrected increase','Purples')\n",
    "    plt.ylim(y_bottom,0)\n",
    "plt.subplot(334)\n",
    "plot_int(spiciness0,pres_int,juld,'SPICINESS0','Blues')\n",
    "plt.subplot(335)\n",
    "plot_int(O2sol,pres_int,juld,'O2SAT','Blues')\n",
    "plt.subplot(336)\n",
    "plot_int(O2sol-data_int['doxy'],pres_int,juld,'AOU (O2SAT - DOXY_ADJUSTED)','Blues')\n",
    "plt.subplot(337)\n",
    "plot_int(ds_int['sigma0'],pres_int,juld,'sigma0','hot')\n",
    "plt.subplot(338)\n",
    "plt.title('Placeholder for Ds')\n",
    "plt.subplot(339)\n",
    "plt.title('Placeholder for Dl')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(wmoid)+'/fig-extra-'+str(wmoid),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Saving to netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If NPQ correction was done, replace the chlorophyll-a array\n",
    "if count_npq > 0:\n",
    "    ds_int['CHLA_ADJUSTED_AR'].values = chla_npq\n",
    "\n",
    "# Add metadata\n",
    "ds_int.attrs['title'] = 'Analysis-ready BGC-Argo float time series'\n",
    "ds_int.attrs['institution'] = 'Japan Agency for Marine-Earth Science and Technology (JAMSTEC)'\n",
    "ds_int.attrs['notes'] = 'Reference: Fujishima and Hayashida (2026): Jupyter Notebook for generating analysis-ready BGC-Argo float time series, Journal of Open Source Software'\n",
    "ds_int.attrs['history'] = 'Created on ' + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "# Save to NetCDF\n",
    "ds_int.to_netcdf(str(wmoid)+'/AR'+str(wmoid)+'.nc')\n",
    "\n",
    "print(ds_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
