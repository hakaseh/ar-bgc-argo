{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ***Search*** for a BGC-Argo float of your interest\n",
    "\n",
    "- lon0: the western edge of the box (range: -180 to 180 deg)\n",
    "- lon1: the eastern edge of the box\n",
    "- lat0: the southern edge of the box (range: -90 to 90 deg)\n",
    "- lat1: the western edge of the box\n",
    "- date0: the first date (format: yyyymmdd)\n",
    "- date1: the last date\n",
    "- mindays: the minimum number of days of data required (e.g., 365 days = there are at least 365 days between the first and last profiles)\n",
    "- minfreq: the minimum number of sampling frequency (e.g., 14 days = at least one profile every 14 days on average)\n",
    "- maxdrift: the maximum drifting speed of the float. Useful for 1-d modelling, in which we want floats that are drifting slowly. For drifting speed, refer to Katsumata and Yoshinari (2010), https://doi.org/10.1007/s10872-010-0046-4\n",
    "- medseamask: Set to `True` if you want to exclude the Mediterranean Sea from search. Otherwise set to `False`.\n",
    "- list_var: list of BGC variables (CHLA, BBP700, NITRATE, DOWNWELLING_PAR, DOXY, PH_IN_SITU_TOTAL, CDOM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">--- User input begins ---</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon0 = -180 \n",
    "lon1 = 180 \n",
    "lat0 = -90 \n",
    "lat1 = 90 \n",
    "date0 = 20210101\n",
    "date1 = 20240131\n",
    "mindays = 365*1\n",
    "minfreq = 30\n",
    "maxdrift = 0.05\n",
    "medseamask = True\n",
    "full_sensors = ['CHLA','BBP700','NITRATE','DOWNWELLING_PAR','DOXY','PH_IN_SITU_TOTAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">--- User input ends ---</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cft \n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in km\n",
    "\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    \n",
    "    # Handle longitude difference with wrapping around the 180° meridian\n",
    "    dlon = radians((lon2 - lon1 + 360) % 360)  # Normalize to [0, 360)\n",
    "    if dlon > radians(180):\n",
    "        dlon -= radians(360)  # Shorten distance across the 180° meridian\n",
    "\n",
    "    a = sin(dlat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "def calculate_area(min_lat, min_lon, max_lat, max_lon):\n",
    "    # Approximate width using the distance between min_lon and max_lon at the midpoint latitude\n",
    "    mid_lat = (min_lat + max_lat) / 2\n",
    "    width = haversine_distance(mid_lat, min_lon, mid_lat, max_lon)\n",
    "    \n",
    "    # Approximate height using the distance between min_lat and max_lat at the midpoint longitude\n",
    "    height = haversine_distance(min_lat, min_lon, max_lat, min_lon)\n",
    "    \n",
    "    return width * height  # Area in km²\n",
    "\n",
    "def calculate_float_speed(lon,lat,date):\n",
    "    # NOTE that this represents the overall mean speed and not the mean of the instantaneous speed (between cycles). \n",
    "    # This prevents from division by zero when there are multiple sampling (especially in the first day of deployment).\n",
    "    # We should be careful about this when automating analysis.\n",
    "    \n",
    "    # Earth's radius in meters\n",
    "    R = 6371000  \n",
    "    # convert to radians\n",
    "    lon_rad = np.radians(np.array(lon))\n",
    "    lat_rad = np.radians(np.array(lat))\n",
    "    # take the difference\n",
    "    delta_lon = lon_rad[1:] - lon_rad[:-1]\n",
    "    delta_lat = lat_rad[1:] - lat_rad[:-1]\n",
    "    # Haversine formula\n",
    "    a = np.sin(delta_lat / 2)**2 + np.cos(lat_rad[:-1]) * np.cos(lat_rad[1:]) * np.sin(delta_lon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distances = R * c  # in meters\n",
    "    # Time differences in days\n",
    "    time_deltas = (np.array(date)[1:] - np.array(date)[:-1]).astype('timedelta64[D]').astype(int)\n",
    "    # Speed in meters per second\n",
    "    speed = np.sum(distances) / np.sum(time_deltas) / 86400.\n",
    "    # average speed\n",
    "    return speed\n",
    "\n",
    "def contains_points_in_MedSea(lon, lat):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        bool: True if any point is inside the box, False otherwise\n",
    "    \"\"\"    \n",
    "    within_lon = (np.array(lon) >= -5) & (np.array(lon) <= 37)\n",
    "    within_lat = (np.array(lat) >= 30) & (np.array(lat) <= 45)\n",
    "    \n",
    "    return np.any(within_lon & within_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "<a id=\"jump_bgc-argo\"></a>\n",
    "### Retrieve the latest Argo index from the website / 最新のアルゴデータインデックス(カタログ)を読み込む\n",
    "- This index can also be viewed from your browser / カタログはブラウザからも閲覧できる: https://data-argo.ifremer.fr/argo_synthetic-profile_index.txt\n",
    "- Note this process can take some time (for a minute or so) as the index is relatively large (MBs) and the server can be slow / カタログの容量が大きいこととサーバーが遅い時があるため、カタログを読み込むのに１分ほど時間を要することがある。\n",
    "- `skiprows = 8`: Ignore the first 8 rows which are irrelevant / カタログの最初の８行は必要ないので無視する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://data-argo.ifremer.fr/argo_synthetic-profile_index.txt',skiprows=8)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Filter the profile list based on your requirements / 検索条件に応じたリストを作成する\n",
    "Personal note:\n",
    "- Run this cell even if you want for the whole region. this filtering helps remove the data with NaN values for dates.\n",
    "- Some of the inputs above (i.e., mindays, minfreq, maxdrift, medseamask) will not affect the result (but they will affect the map and time series further below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the dataset based on lon, lat, and variables. Date has a weird format so extract first then postprocess dates\n",
    "datasub = data[(data['longitude'] >= lon0) & (data['longitude'] <= lon1) & (data['latitude'] >= lat0) &\n",
    "               (data['latitude'] <= lat1) & (data['date'] >= 0)]\n",
    "\n",
    "for i in range(len(full_sensors)):\n",
    "    datasub = datasub[datasub['parameters'].str.contains(full_sensors[i])]\n",
    "\n",
    "#add a new variable called 'time'\n",
    "timestr = [str(num) for num in datasub['date']]\n",
    "timestr = [num[8:8+6] for num in timestr]\n",
    "timeint = [int(num) for num in timestr]\n",
    "datasub.loc[:,'time'] = timeint\n",
    "\n",
    "#modify the date format to be yyyymmdd\n",
    "datestr = [str(num) for num in datasub['date']]\n",
    "datestr = [num[0:8] for num in datestr]\n",
    "dateint = [int(num) for num in datestr]\n",
    "datasub.loc[:,'date'] = dateint\n",
    "#refine the dataset based on the selected period\n",
    "datasub = datasub[(datasub['date'].values >= date0) & (datasub['date'].values <= date1)]\n",
    "datasub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Visualize the search results as a map and time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!mkdir -p search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "fig2 = plt.figure(figsize=(8,6))\n",
    "ax2 = fig2.add_subplot(1,1,1)\n",
    "cmap20 = plt.colormaps['tab20']\n",
    "tab20_colors = [cmap20(i) for i in range(20)]  # List of 20 RGBA tuples\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1,projection= ccrs.PlateCarree(central_longitude=270)) #InterruptedGoodeHomolosine\n",
    "ax1.add_feature(cft.LAND)\n",
    "#ax1.coastlines(resolution='50m')\n",
    "ax1.set_extent([lon0, lon1, lat0, lat1], crs=ccrs.PlateCarree())\n",
    "gl = ax1.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False,color = \"None\")\n",
    "gl.top_labels=False\n",
    "gl.right_labels=False\n",
    "\n",
    "#temporary list for tracking float info\n",
    "floatid_cur = 0\n",
    "floatnum = []\n",
    "floatsta = []\n",
    "floatend = []\n",
    "floatlon = []\n",
    "floatlat = []\n",
    "floatdate = []\n",
    "daimei = []\n",
    "#list for saving the float infomation\n",
    "lines = []\n",
    "\n",
    "#index for floats\n",
    "abci = 0\n",
    "#loop over each profile\n",
    "for i in range(datasub.shape[0]):\n",
    "    #float id: obtain from the file path split by slash (/) and grab the second index (after the first and second slashes)\n",
    "    floatid = datasub['file'].values[i].split('/')[1]\n",
    "    #in the first iteration, save the id and start date\n",
    "    if i == 0: \n",
    "        floatnum.append(floatid)\n",
    "        floatsta.append(datasub['date'].values[i])\n",
    "        floatlon.append(datasub['longitude'].values[i])\n",
    "        floatlat.append(datasub['latitude'].values[i]) \n",
    "        floatdate.append(datetime.strptime(str(int(datasub['date'].values[i])),'%Y%m%d'))\n",
    "        floatid_cur = floatid\n",
    "    # for the rest of the iteration\n",
    "    else:\n",
    "        # accumulate lon,lat if still the same float\n",
    "        if floatid == floatid_cur:\n",
    "            floatlon.append(datasub['longitude'].values[i])\n",
    "            floatlat.append(datasub['latitude'].values[i])\n",
    "            floatdate.append(datetime.strptime(str(int(datasub['date'].values[i])),'%Y%m%d'))\n",
    "        # if it is a new float, plot the results of the previous float\n",
    "        else:\n",
    "            if len(floatdate) > 1: # ignore if there is only one profile\n",
    "                # Check for the three criteria based on frequency and duration of the profiling and drift speed\n",
    "                valid_freq = np.max(np.diff(floatdate)).days < minfreq\n",
    "                valid_drift = calculate_float_speed(floatlon,floatlat,floatdate) < maxdrift\n",
    "                valid_dur = max(floatdate)-min(floatdate) > timedelta(days=mindays)\n",
    "                # only plot the floats that are longer than mindays AND drifting slower than maxdrift AND minfreq satisfied\n",
    "                if valid_freq and valid_drift and valid_dur:\n",
    "                    if not medseamask or (medseamask and not contains_points_in_MedSea(floatlon, floatlat)):                        \n",
    "                        ax1.scatter(floatlon,floatlat,color=tab20_colors[abci % len(tab20_colors)],transform=ccrs.PlateCarree(),zorder=3,s=0.1)\n",
    "                        ax1.scatter(floatlon[-1],floatlat[-1],color='k',marker='.',transform=ccrs.PlateCarree(),zorder=4,s=6)\n",
    "                        ax1.text(floatlon[-1],floatlat[-1],abci+1,color='k',transform=ccrs.PlateCarree(),zorder=5,fontsize=5)\n",
    "                        for k in range(np.size(floatdate)):\n",
    "                            ax2.scatter(floatdate[k],abci,color=tab20_colors[abci % len(tab20_colors)],marker='|',linewidths=0.1)\n",
    "                        daimei.append(floatnum[-1]+'('+str(abci+1)+')')\n",
    "                        abci += 1\n",
    "                        lines.append(str(floatnum[-1])+','+\n",
    "                                     str(round(0.5*(min(floatlon)+max(floatlon)),2))+','+\n",
    "                                     str(round(0.5*(min(floatlat)+max(floatlat)),2))+','+\n",
    "                                     str(floatdate[0].strftime(\"%Y%m%d\"))+','+\n",
    "                                     str(floatdate[-1].strftime(\"%Y%m%d\"))+','+\n",
    "                                     str(len(floatdate))\n",
    "                                    )\n",
    "            floatlon = []\n",
    "            floatlat = []\n",
    "            floatdate = []\n",
    "            #floatstatus = []\n",
    "            floatend.append(datasub['date'].values[i-1])\n",
    "            floatsta.append(datasub['date'].values[i])\n",
    "            floatid_cur = floatid\n",
    "            floatnum.append(floatid)\n",
    "            floatlon.append(datasub['longitude'].values[i])\n",
    "            floatlat.append(datasub['latitude'].values[i])\n",
    "            floatdate.append(datetime.strptime(str(int(datasub['date'].values[i])),'%Y%m%d'))\n",
    "# end of the loop over the profiles\n",
    "if len(floatdate) > 1: # ignore if there is only one profile\n",
    "    # Check for the three criteria based on frequency and duration of the profiling and drift speed\n",
    "    valid_freq = np.max(np.diff(floatdate)).days < minfreq\n",
    "    valid_drift = calculate_float_speed(floatlon,floatlat,floatdate) < maxdrift\n",
    "    valid_dur = max(floatdate)-min(floatdate) > timedelta(days=mindays)\n",
    "    # only plot the floats that are longer than mindays AND drifting slower than maxdrift AND minfreq satisfied\n",
    "    if valid_freq and valid_drift and valid_dur:\n",
    "        if not medseamask or (medseamask and not contains_points_in_MedSea(floatlon, floatlat)):                        \n",
    "            #plot the remaining float\n",
    "            ax1.scatter(floatlon,floatlat,color=tab20_colors[abci % len(tab20_colors)],transform=ccrs.PlateCarree(),zorder=3,s=0.1)\n",
    "            ax1.scatter(floatlon[-1],floatlat[-1],color='k',marker='.',transform=ccrs.PlateCarree(),zorder=4,s=6)\n",
    "            ax1.text(floatlon[-1],floatlat[-1],abci+1,color='k',transform=ccrs.PlateCarree(),zorder=5,fontsize=5)\n",
    "            floatend.append(datasub['date'].values[i])\n",
    "            for k in range(np.size(floatdate)):\n",
    "                ax2.scatter(floatdate[k],abci,color=tab20_colors[abci % len(tab20_colors)],marker='|',linewidths=0.1)\n",
    "            daimei.append(floatnum[-1]+'('+str(abci+1)+')')\n",
    "            lines.append(str(floatnum[-1])+','+\n",
    "                         str(round(0.5*(min(floatlon)+max(floatlon)),2))+','+\n",
    "                         str(round(0.5*(min(floatlat)+max(floatlat)),2))+','+\n",
    "                         str(floatdate[0].strftime(\"%Y%m%d\"))+','+\n",
    "                         str(floatdate[-1].strftime(\"%Y%m%d\"))+','+\n",
    "                         str(len(floatdate))\n",
    "                        )\n",
    "\n",
    "#save the current time for creating a unique id for the outputs.\n",
    "now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "# saving the map\n",
    "plt.tight_layout()\n",
    "fig.savefig('search/map_search_'+now,dpi=300,bbox_inches='tight')\n",
    "\n",
    "# saving the time series\n",
    "ax2.set_yticks(range(np.size(daimei)), daimei)\n",
    "ax2.set_xlim(datetime.strptime(str(date0),'%Y%m%d'),datetime.strptime(str(date1),'%Y%m%d'))\n",
    "ax2.set_ylabel('WMO ID (label)')\n",
    "ax2.yaxis.label.set_horizontalalignment('left')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "fig2.savefig('search/ts_search_'+now,dpi=300,bbox_inches='tight')\n",
    "\n",
    "# create a copy of this notebook for reference\n",
    "!cp search.ipynb search/search_{now}.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
